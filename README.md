# MNIST æ‰‹å†™æ•°å­—è¯†åˆ«ï¼ˆPyTorch å®ç°ï¼‰

ä¸€ä¸ªåŸºäº **PyTorch + è‡ªå®šä¹‰ MNIST è§£æ** çš„æ·±åº¦å­¦ä¹ é¡¹ç›®ã€‚  
æœ¬é¡¹ç›®å®Œæ•´å±•ç¤ºäº†ä» **è¯»å–åŸç”Ÿ IDX æ ¼å¼æ•°æ® â†’ æ„å»º Dataset â†’ å®šä¹‰æ¨¡å‹ â†’ è®­ç»ƒ â†’ ä¿å­˜æ¨¡å‹ â†’ æµ‹è¯•** çš„å®Œæ•´æµç¨‹ã€‚

**é¡¹ç›®äº®ç‚¹ï¼š**

- ä¸ä½¿ç”¨ `torchvision.datasets.MNIST`ï¼Œè€Œæ˜¯æ‰‹åŠ¨è§£æ IDX æ•°æ®é›†  
- è‡ªå®šä¹‰ `Dataset` & `DataLoader`  
- å®ç°ä¸€ä¸ªç®€å•çš„ MLP ç¥ç»ç½‘ç»œ  
- æ”¯æŒ CPU / GPU / Apple MPS è‡ªåŠ¨åˆ‡æ¢  
- è®­ç»ƒè„šæœ¬ä¸æµ‹è¯•è„šæœ¬åˆ†ç¦»  
- å·¥ç¨‹ç»“æ„æ¸…æ™°ï¼Œé€‚åˆä½œä¸º PyTorch å…¥é—¨æ¨¡ç‰ˆ  

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```bash
MNIST/
â”‚
â”œâ”€â”€ data/                      # MNIST åŸå§‹æ•°æ®ï¼ˆidxã€gzï¼‰
â”‚   â”œâ”€â”€ train-images-idx3-ubyte.gz
â”‚   â”œâ”€â”€ train-labels-idx1-ubyte.gz
â”‚   â”œâ”€â”€ t10k-images-idx3-ubyte.gz
â”‚   â””â”€â”€ t10k-labels-idx1-ubyte.gz
â”‚
â”œâ”€â”€ program/
â”‚   â”œâ”€â”€ mnist_dataset.py       # è‡ªå®šä¹‰ Dataset + DataLoaderï¼ˆè§£æ IDXï¼‰
â”‚   â”œâ”€â”€ model.py               # MLP æ¨¡å‹ç»“æ„ SimpleMLP
â”‚   â”œâ”€â”€ utils.py               # è®­ç»ƒä¸è¯„ä¼°å‡½æ•°ï¼štrain_one_epoch / eval_model
â”‚   â”œâ”€â”€ train_mnist.py         # è®­ç»ƒè„šæœ¬ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒï¼Œä¿å­˜ mnist_mlp.pth
â”‚   â””â”€â”€ test_mnist.py          # æµ‹è¯•è„šæœ¬ï¼šåŠ è½½æ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
â”‚
â”œâ”€â”€ mnist_mlp.pth              # è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ï¼ˆé€šå¸¸é€šè¿‡ .gitignore å¿½ç•¥ï¼‰
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ› ï¸ ç¯å¢ƒé…ç½®

å»ºè®®ä½¿ç”¨ Conda åˆ›å»ºç‹¬ç«‹ç¯å¢ƒï¼š

conda create -n mnist-env python=3.10
conda activate mnist-env


å®‰è£…ä¾èµ–ï¼š

pip install torch torchvision numpy pillow matplotlib tqdm


å¯é€‰ï¼šæ£€æŸ¥ GPUï¼ˆæˆ– Apple MPSï¼‰æ˜¯å¦å¯ç”¨ï¼š

import torch
print("CUDA:", torch.cuda.is_available())
print("MPS:", torch.backends.mps.is_available())

ğŸ“¥ ä¸‹è½½ MNIST æ•°æ®é›†

MNIST å®˜æ–¹ä¸‹è½½åœ°å€ï¼ˆIDX æ ¼å¼ï¼‰ï¼š

https://storage.googleapis.com/cvdf-datasets/mnist/

éœ€è¦ä¸‹è½½ä»¥ä¸‹ 4 ä¸ª .gz æ–‡ä»¶ï¼Œå¹¶æ”¾å…¥é¡¹ç›®ä¸­çš„ data/ ç›®å½•ä¸‹ï¼š

train-images-idx3-ubyte.gz

train-labels-idx1-ubyte.gz

t10k-images-idx3-ubyte.gz

t10k-labels-idx1-ubyte.gz

é¡¹ç›®ä¸­å·²å†…ç½®è§£å‹é€»è¾‘ï¼Œé¦–æ¬¡è¿è¡Œå‰å¯æ‰§è¡Œï¼š

cd MNIST
python program/mnist_dataset.py


å¦‚æœè§£å‹æˆåŠŸï¼Œä¼šçœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š

[INFO] è§£å‹: train-images-idx3-ubyte.gz -> train-images-idx3-ubyte
[DONE] MNIST è§£å‹å®Œæˆï¼

ğŸ§± ä»£ç æ¨¡å—è¯´æ˜
1. æ•°æ®é›†ä¸ DataLoaderï¼ˆmnist_dataset.pyï¼‰

æ‰‹åŠ¨è§£æ MNIST çš„ IDX æ–‡ä»¶ï¼ˆå›¾åƒä¸æ ‡ç­¾ï¼‰

å®ç° read_idx_images ä¸ read_idx_labels

å°è£…ä¸º MNISTIdxDataset(Dataset)ï¼Œè¿”å› (image, label)

æä¾›ï¼š

train_loader  # è®­ç»ƒé›† DataLoader
test_loader   # æµ‹è¯•é›† DataLoader

2. æ¨¡å‹ï¼ˆmodel.pyï¼‰

ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç»“æ„ï¼š

class SimpleMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28 * 28, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)   # [B, 1, 28, 28] -> [B, 784]
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)             # logits [B, 10]
        return x

3. è®­ç»ƒä¸è¯„ä¼°è¾…åŠ©å‡½æ•°ï¼ˆutils.pyï¼‰

train_one_epoch(model, optimizer, criterion, train_loader, device, epoch)

åœ¨è®­ç»ƒé›†ä¸Šè·‘ä¸€æ•´è½®ï¼ˆä¸€ä¸ª epochï¼‰

æ¯ 100 ä¸ª batch æ‰“å°ä¸€æ¬¡å¹³å‡æŸå¤±

eval_model(model, criterion, test_loader, device)

åˆ‡æ¢åˆ° model.eval() æ¨¡å¼

ä¸è®¡ç®—æ¢¯åº¦ï¼ˆtorch.no_grad()ï¼‰

è¿”å›ï¼šavg_loss, acc

4. è®­ç»ƒè„šæœ¬ï¼ˆtrain_mnist.pyï¼‰

è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆMPS / CUDA / CPUï¼‰

åˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨

åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒè‹¥å¹²ä¸ª epoch

è®­ç»ƒå®Œæ¯•åä¿å­˜æ¨¡å‹æƒé‡åˆ° mnist_mlp.pth

ğŸš€ è®­ç»ƒæ¨¡å‹

åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼š

cd MNIST
python program/train_mnist.py


ä½ å°†ä¼šçœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼ˆç¤ºä¾‹ï¼‰ï¼š

Using device: mps
Epoch [1] Step [100/938] Loss: 0.8833
Epoch [1] Step [200/938] Loss: 0.4134
...
Epoch [5] Step [900/938] Loss: 0.0744
è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ä¸º mnist_mlp.pth


è®­ç»ƒè¿‡ç¨‹ä¸­ ä¸ä¼šä½¿ç”¨æµ‹è¯•é›†ï¼Œä»¥é¿å…â€œå·çœ‹â€æµ‹è¯•é›†ï¼Œä¿æŒè¯„ä¼°çš„ä¸¥æ ¼æ€§ã€‚

ğŸ” æµ‹è¯•æ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼š

python program/test_mnist.py


è¯¥è„šæœ¬ä¼šï¼š

åŠ è½½ mnist_mlp.pth

åœ¨ test_loaderï¼ˆæµ‹è¯•é›†ï¼‰ä¸Šå‰å‘è®¡ç®—

è¾“å‡ºæµ‹è¯•é›†çš„å¹³å‡ Loss ä¸ Accuracy

ç¤ºä¾‹è¾“å‡ºï¼š

Using device: mps
æ¨¡å‹æƒé‡å·²åŠ è½½ï¼šmnist_mlp.pth
Test Loss: 0.0567
Test Accuracy: 98.15%
